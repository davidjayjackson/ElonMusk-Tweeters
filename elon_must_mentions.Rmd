---
title: 'Elon Musk: Tweet Mentions'
author: "David Jackson"
date: "`r Sys.Date()`"
output: 
  html_document: 
    fig_height: 20
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidytext)
library(lubridate)
library(scales)
library(odbc)
library(DBI)
```

```{r}
# Connect to Elon Musk Tweets DB on MSSQL 2019
con <- DBI::dbConnect(odbc::odbc(), 
                      Driver = "SQL Server", 
                      Server = "localhost\\SQLEXPRESS", 
                      Database = "elonmusk", 
                      Trusted_Connection = "True")
```


## Pull Tweets that Mention Elon Musk

```{r}
# Grab field names
dbListFields(con,"elonMentions")
```
```{r}
mentions <- dbGetQuery(con,"select date,username,
            content FROM elonMentions;")
```

```{r}
mentions %>% count(date,sort =T) %>% ggplot() + geom_col(aes(x=date,y=n)) + labs(title ="Elon Must Mentions by Day",
                                                                                 y="Number of Mentiions")
```

```{r}
mentions %>% count(username,sort=T) %>% slice_max(n,n=10) %>%
  ggplot() + geom_col(aes(x=reorder(username,n),username,y=n)) +
  coord_flip() + labs(title = "Top 10 Mentions by Username",x="Username",y="Count of Mentions")
```
## Begin Text Analysis

```{r}
content <- mentions %>% select(content) %>% rename(txt = content)
```
```{r}
word_tokens <- content %>% unnest_tokens(word, txt)
```

```{r}
# dbWriteTable(con, "tokens",content_words ,overwrite=TRUE)
```

## PUll down cleaner words

```{r}
tokens <- dbGetQuery(con,"select word FROM tokens;")

data(stop_words)

tidy_tokens <- tokens %>%
  anti_join(stop_words)
dbWriteTable(con, "tokens",tidy_tokens ,overwrite=TRUE)
```
## Count Tokens and Plot

```{r}
tidy_tokens %>% count(word,sort =T) %>% 
  filter(!word %in% c("https","de","la")) %>%
  filter(n >500) %>% ggplot() +
    geom_col(aes(x=reorder(word,n),y=n)) + coord_flip() +
  labs(title = "Words That Appear More than 500 Times")
```

```{r}
# tidy_tokens %>% count(word,sort =T) %>% 
#   filter(!word %in% c("https","de","la")) %>%
#   filter(n <= 15000) %>% ggplot() +
#     geom_col(aes(x=reorder(word,n),y=n)) + coord_flip() +
#   labs(title = "Words That Appear <= 15000 Times")
```

## Fun with GGWordCloud

```{r}
library(ggwordcloud)
 wc <- tidy_tokens %>% count(word,sort =T) %>% 
  filter(!word %in% c("https","de","la")) 
```
```{r}
set.seed(345)
wc %>% filter(n >=250) %>% ggplot(aes(label = word)) +   geom_text_wordcloud() 
  
```

